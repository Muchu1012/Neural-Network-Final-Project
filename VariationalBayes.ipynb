{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c1e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b9e078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/a1012/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取并清洗数据...\n",
      "正在生成 TF-IDF 特征向量...\n",
      "预处理完成！\n",
      "训练集大小: torch.Size([4137, 5000])\n",
      "测试集大小: torch.Size([1035, 5000])\n"
     ]
    }
   ],
   "source": [
    "#数据预处理\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_email_text(text):\n",
    "    \"\"\"\n",
    "    清洗单封邮件文本\n",
    "    \"\"\"\n",
    "    # 1. 转换为小写\n",
    "    text = text.lower()\n",
    "    # 2. 去除邮件头 (Subject, From, To 等关键词)\n",
    "    text = re.sub(r'(subject:|to:|cc:|from:)', ' ', text)\n",
    "    # 3. 去除转发信息和特殊分割线\n",
    "    text = re.sub(r'(-+|_+|\\|)', ' ', text)\n",
    "    # 4. 去除数字和非字母字符\n",
    "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
    "    # 5. 去除多余空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # 6. 分词、去停用词、词干提取\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    ps = PorterStemmer()\n",
    "    words = text.split()\n",
    "    cleaned_words = [ps.stem(w) for w in words if w not in stop_words]\n",
    "    \n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "def load_data(legitimate_path, spam_path):\n",
    "    \"\"\"\n",
    "    读取文件夹中的所有txt文件\n",
    "    \"\"\"\n",
    "    emails = []\n",
    "    labels = []\n",
    "    \n",
    "    # 读取正常邮件 (Label 0)\n",
    "    for filename in os.listdir(legitimate_path):\n",
    "        with open(os.path.join(legitimate_path, filename), 'r', encoding='latin-1') as f:\n",
    "            emails.append(clean_email_text(f.read()))\n",
    "            labels.append(0)\n",
    "            \n",
    "    # 读取垃圾邮件 (Label 1)\n",
    "    for filename in os.listdir(spam_path):\n",
    "        with open(os.path.join(spam_path, filename), 'r', encoding='latin-1') as f:\n",
    "            emails.append(clean_email_text(f.read()))\n",
    "            labels.append(1)\n",
    "            \n",
    "    return emails, labels\n",
    "\n",
    "\n",
    "legit_dir = 'enron1/ham'\n",
    "spam_dir = 'enron1/spam'\n",
    "\n",
    "print(\"正在读取并清洗数据...\")\n",
    "texts, y = load_data(legit_dir, spam_dir)\n",
    "\n",
    "# 4. TF-IDF 特征提取 (限制为 5000 维)\n",
    "print(\"正在生成 TF-IDF 特征向量...\")\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(texts).toarray()\n",
    "\n",
    "# 5. 转换为 PyTorch 张量\n",
    "X_tensor = torch.FloatTensor(X)\n",
    "y_tensor = torch.LongTensor(y)\n",
    "\n",
    "# 6. 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y_tensor\n",
    ")\n",
    "\n",
    "print(f\"预处理完成！\")\n",
    "print(f\"训练集大小: {X_train.shape}\")\n",
    "print(f\"测试集大小: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73402774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义变分线性层 (Variational Linear Layer)\n",
    "class VariationalLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, prior_sigma=1.0):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # 权重均值 (mu) 和偏置均值\n",
    "        self.w_mu = nn.Parameter(torch.Tensor(out_features, in_features).normal_(0, 0.1))\n",
    "        self.b_mu = nn.Parameter(torch.Tensor(out_features).normal_(0, 0.1))\n",
    "        \n",
    "        # 权重标准差的对数 (rho)，使用 rho 是为了确保 sigma = log(1 + exp(rho)) 始终为正\n",
    "        self.w_rho = nn.Parameter(torch.Tensor(out_features, in_features).fill_(-3.0))\n",
    "        self.b_rho = nn.Parameter(torch.Tensor(out_features).fill_(-3.0))\n",
    "        \n",
    "        # 先验分布的标准差\n",
    "        self.prior_sigma = prior_sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. 重参数化技巧: w = mu + sigma * epsilon\n",
    "        w_sigma = torch.log(1 + torch.exp(self.w_rho))\n",
    "        b_sigma = torch.log(1 + torch.exp(self.b_rho))\n",
    "        \n",
    "        epsilon_w = torch.randn_like(w_sigma)\n",
    "        epsilon_b = torch.randn_like(b_sigma)\n",
    "        \n",
    "        w = self.w_mu + w_sigma * epsilon_w\n",
    "        b = self.b_mu + b_sigma * epsilon_b\n",
    "        \n",
    "        # 2. 计算 KL 散度 (假设先验为标准正态分布 N(0, prior_sigma^2))\n",
    "        # 这里的 KL 散度简化为解析形式\n",
    "        kl_w = torch.log(self.prior_sigma / w_sigma) + (w_sigma**2 + self.w_mu**2) / (2 * self.prior_sigma**2) - 0.5\n",
    "        kl_b = torch.log(self.prior_sigma / b_sigma) + (b_sigma**2 + self.b_mu**2) / (2 * self.prior_sigma**2) - 0.5\n",
    "        self.kl_loss = kl_w.sum() + kl_b.sum()\n",
    "        \n",
    "        return F.linear(x, w, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4002eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建变分贝叶斯神经网络 (BNN)\n",
    "class BayesianSpamClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = VariationalLinear(input_dim, 256)\n",
    "        self.layer2 = VariationalLinear(256, 2) # 二分类：Spam vs Legitimate\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "    def get_kl_loss(self):\n",
    "        return self.layer1.kl_loss + self.layer2.kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20bce64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_uncertainty(model, x, num_samples=10):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            # 这里的 model(x) 会触发 VariationalLinear 的随机采样\n",
    "            outputs = model(x)\n",
    "            results.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "    \n",
    "    results = np.array(results)  # [Samples, Batch, Classes]\n",
    "    mean_pred = results.mean(axis=0)\n",
    "    # 计算类别概率的方差，作为模型不确定性的度量\n",
    "    uncertainty = results.var(axis=0).sum(axis=1) \n",
    "    return mean_pred, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c6ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练逻辑与 ELBO 损失\n",
    "def train_step(model, optimizer, data, target, num_samples=5):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 变分推断通过多次采样来逼近期望\n",
    "    total_nll = 0\n",
    "    for _ in range(num_samples):\n",
    "        output = model(data)\n",
    "        # 考虑类别不平衡：给 Spam 类 (假设为1) 更高的权重\n",
    "        weight = torch.tensor([1.0, 2.45]).to(data.device) \n",
    "        total_nll += F.cross_entropy(output, target, weight=weight)\n",
    "    \n",
    "    avg_nll = total_nll / num_samples\n",
    "    kl_loss = model.get_kl_loss() / 5975 # 按照总样本数归一化\n",
    "    \n",
    "    # ELBO = - (NLL + KL) -> 最小化负 ELBO\n",
    "    loss = avg_nll + kl_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e7154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练步骤... (训练样本数: 3620)\n",
      "Epoch 1/20, Average Loss: 536.8036\n",
      "Epoch 2/20, Average Loss: 524.3176\n",
      "Epoch 3/20, Average Loss: 512.2341\n",
      "Epoch 4/20, Average Loss: 500.2995\n",
      "Epoch 5/20, Average Loss: 488.4512\n",
      "Epoch 6/20, Average Loss: 476.6684\n",
      "Epoch 7/20, Average Loss: 464.9416\n",
      "Epoch 8/20, Average Loss: 453.2673\n",
      "Epoch 9/20, Average Loss: 441.6449\n",
      "Epoch 10/20, Average Loss: 430.0746\n",
      "Epoch 11/20, Average Loss: 418.5578\n",
      "Epoch 12/20, Average Loss: 407.0972\n",
      "Epoch 13/20, Average Loss: 395.6943\n",
      "Epoch 14/20, Average Loss: 384.3550\n",
      "Epoch 15/20, Average Loss: 373.0793\n",
      "Epoch 16/20, Average Loss: 361.8732\n",
      "Epoch 17/20, Average Loss: 350.7396\n",
      "Epoch 18/20, Average Loss: 339.6835\n",
      "Epoch 19/20, Average Loss: 328.7098\n",
      "Epoch 20/20, Average Loss: 317.8231\n",
      "\n",
      "开始在测试集上评估... (测试样本数: 1552)\n",
      "\n",
      "==============================\n",
      "测试集准确率: 98.32%\n",
      "详细分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.99      0.98      0.99      1102\n",
      "        Spam       0.96      0.98      0.97       450\n",
      "\n",
      "    accuracy                           0.98      1552\n",
      "   macro avg       0.98      0.98      0.98      1552\n",
      "weighted avg       0.98      0.98      0.98      1552\n",
      "\n",
      "混淆矩阵:\n",
      "[[1084   18]\n",
      " [   8  442]]\n",
      "==============================\n",
      "\n",
      "预测示例 (测试集前 3 个样本):\n",
      "样本 1: 真实=Legitimate, 预测=Legitimate, 不确定性(方差)=0.000000\n",
      "样本 2: 真实=Legitimate, 预测=Legitimate, 不确定性(方差)=0.000000\n",
      "样本 3: 真实=Legitimate, 预测=Legitimate, 不确定性(方差)=0.000000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 修改数据集划分比例 \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tensor, y_tensor, test_size=0.3, random_state=42, stratify=y_tensor\n",
    "    )\n",
    "    \n",
    "    #  初始化模型与优化器\n",
    "    input_dim = 5000\n",
    "    model = BayesianSpamClassifier(input_dim=input_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 准备 DataLoader\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # 训练模型\n",
    "    print(f\"开始训练步骤... (训练样本数: {len(X_train)})\")\n",
    "    model.train()\n",
    "    for epoch in range(1, 21): \n",
    "        epoch_loss = 0\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            loss = train_step(model, optimizer, batch_x, batch_y)\n",
    "            epoch_loss += loss\n",
    "        print(f\"Epoch {epoch}/20, Average Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # \n",
    "    # 测试集评估 (这是新增的核心部分)\n",
    "    print(f\"\\n开始在测试集上评估... (测试样本数: {len(X_test)})\")\n",
    "    \n",
    "    def evaluate_test_set(model, X_test, y_test, num_monte_carlo=10):\n",
    "        model.eval()\n",
    "        all_probs = []\n",
    "        with torch.no_grad():\n",
    "            # 贝叶斯预测：通过多次采样取平均值来降低方差\n",
    "            for _ in range(num_monte_carlo):\n",
    "                outputs = model(X_test)\n",
    "                probs = F.softmax(outputs, dim=1)\n",
    "                all_probs.append(probs.numpy())\n",
    "        \n",
    "        # 计算平均概率\n",
    "        mean_probs = np.mean(all_probs, axis=0)\n",
    "        y_pred = np.argmax(mean_probs, axis=1)\n",
    "        \n",
    "        # 计算准确率\n",
    "        correct = (y_pred == y_test.numpy()).sum()\n",
    "        accuracy = correct / len(y_test)\n",
    "        \n",
    "        return y_pred, accuracy\n",
    "\n",
    "    # 执行评估\n",
    "    y_pred, test_acc = evaluate_test_set(model, X_test, y_test)\n",
    "    \n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"测试集准确率: {test_acc:.2%}\")\n",
    "    print(\"详细分类报告:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Legitimate', 'Spam']))\n",
    "    print(\"混淆矩阵:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"=\"*30)\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
